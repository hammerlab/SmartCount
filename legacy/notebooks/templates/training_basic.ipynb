{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic Training Template\n",
    "\n",
    "\n",
    "Notebook to train a relatively basic model (no augmentation) using given parameters and then optionally apply that model to a validation dataset and export a variety of statistics about predictions on that data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "# Required\n",
    "data_dir = None\n",
    "model_dir = None\n",
    "export_dir = None\n",
    "train_image_ids = None\n",
    "val_image_ids = None\n",
    "config_script = None\n",
    "\n",
    "# Optional\n",
    "n_epochs = 10\n",
    "train_init_mode = 'coco'\n",
    "n_steps_per_epoch_train = None\n",
    "n_steps_per_epoch_val = None\n",
    "skip_inference = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert data_dir is not None, 'Must provide \"data_dir\"'\n",
    "assert model_dir is not None, 'Must provide \"model_dir\"'\n",
    "assert export_dir is not None, 'Must provided \"export_dir\"'\n",
    "assert train_image_ids is not None, 'Must provide training image ids'\n",
    "assert val_image_ids is not None, 'Must provide validation image ids'\n",
    "assert config_script is not None, 'Must provide config script location'\n",
    "\n",
    "train_image_ids = train_image_ids.split(',')\n",
    "val_image_ids = val_image_ids.split(',')\n",
    "n_epochs = int(n_epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run $config_script\n",
    "%matplotlib inline\n",
    "\n",
    "import os\n",
    "import os.path as osp\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import papermill as pm\n",
    "import matplotlib.pyplot as plt\n",
    "from mrcnn import visualize as mrcnn_viz\n",
    "from mrcnn import model as mrcnn_model_lib\n",
    "from cvutils.mrcnn import model as mrcnn_model\n",
    "from cvutils.mrcnn.session import init_keras_session\n",
    "from celldom.dataset import CelldomDataset\n",
    "from celldom import seed\n",
    "init_keras_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize output directories\n",
    "os.makedirs(export_dir, exist_ok=True)\n",
    "os.makedirs(model_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show class names being used for training\n",
    "CLASS_NAMES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training dataset\n",
    "train_image_paths = [osp.join(data_dir, img) for img in train_image_ids]\n",
    "dataset_train = CelldomDataset()\n",
    "dataset_train.initialize(train_image_paths, CLASS_NAMES)\n",
    "dataset_train.prepare()\n",
    "\n",
    "# # Validation dataset\n",
    "dataset_val = CelldomDataset()\n",
    "val_image_paths = [osp.join(data_dir, img) for img in val_image_ids]\n",
    "dataset_val.initialize(val_image_paths, CLASS_NAMES)\n",
    "dataset_val.prepare()\n",
    "\n",
    "pm.record('n_train', len(train_image_paths))\n",
    "pm.record('n_val', len(val_image_paths))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_config = CelldomTrainingConfig()\n",
    "\n",
    "# Override certain properties if configured to do so\n",
    "if n_steps_per_epoch_train is not None:\n",
    "    train_config.STEPS_PER_EPOCH = n_steps_per_epoch_train\n",
    "if n_steps_per_epoch_val is not None:\n",
    "    train_config.VALIDATION_STEPS = n_steps_per_epoch_val\n",
    "\n",
    "train_config.display()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = mrcnn_model.get_model(\n",
    "    mode=\"training\", config=train_config, \n",
    "    model_dir=model_dir, init_with=train_init_mode\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ignore these warnings for now as they seem to be irrelevant so far\n",
    "warnings.filterwarnings(\n",
    "    'ignore', category=UserWarning,\n",
    "    message='Converting sparse IndexedSlices to a dense Tensor of unknown shape'\n",
    ")\n",
    "warnings.filterwarnings(\n",
    "    'ignore', category=UserWarning,\n",
    "    message='Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data'\n",
    ")\n",
    "\n",
    "model.train(\n",
    "    dataset_train, dataset_val, \n",
    "    learning_rate=train_config.LEARNING_RATE, \n",
    "    epochs=n_epochs, \n",
    "    layers='heads'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quantification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not skip_inference:\n",
    "    from cvutils.mrcnn import inference as mrcnn_inference\n",
    "    from celldom import inference as celldom_inference\n",
    "\n",
    "    inference_config = CelldomInferenceConfig()\n",
    "    model = mrcnn_model.get_model('inference', inference_config, model_dir, init_with='last')\n",
    "\n",
    "    pred_gen = mrcnn_inference.prediction_generator(model, dataset_val)\n",
    "    analysis_fns = celldom_inference.get_default_analysis_fns()\n",
    "    df = pd.DataFrame([celldom_inference.analyze_prediction(p, analysis_fns) for p in pred_gen])\n",
    "    \n",
    "    export_path = osp.join(export_dir, 'stats.pkl')\n",
    "    pm.record('stats_path', export_path)\n",
    "    df.to_pickle(export_path)"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
